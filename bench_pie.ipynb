{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d9be3a-a499-4fbb-b0f5-8ab8f62fcabd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from math import ceil\n",
    "from time import sleep\n",
    "from itertools import product\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "from threading import Event\n",
    "import signal\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "005fc6d4-7115-428b-9c0d-23ce2f8f00e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ORIGIN_DIR = \"/gpfsdswork/projects/idris/sos/ssos039/bench_pie/benches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "861975e7-62b3-44b1-8844-884dcf45cb05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_slurm_string(parameters):\n",
    "    \n",
    "    model_name = parameters[\"model_name\"]\n",
    "    training_dist = parameters[\"training_dist\"]\n",
    "    nbr_gpu = parameters[\"nbr_gpu\"]\n",
    "    \n",
    "    batch_size = parameters[\"batch_size\"]\n",
    "    max_length = parameters[\"max_length\"]\n",
    "    is_debug = parameters[\"is_debug\"]\n",
    "    \n",
    "    if is_debug:\n",
    "        debug = \"--debug\"\n",
    "    else:\n",
    "        debug = \"\"\n",
    "    \n",
    "    if nbr_gpu == 16:\n",
    "        nbr_node = 2\n",
    "        nbr_gpu = 8\n",
    "    else:\n",
    "        nbr_node = 1\n",
    "        \n",
    "    if nbr_gpu == 8:\n",
    "        exclu = \"#SBATCH --exclusive\"\n",
    "    else:\n",
    "        exclu = \"\"\n",
    "        \n",
    "    if training_dist == \"fsdp\":\n",
    "        stage = 1\n",
    "        ddp = training_dist\n",
    "    else:\n",
    "        stage = training_dist[-1]\n",
    "        ddp = training_dist[:-1]\n",
    "        \n",
    "    slurm_string = f\"\"\"#!/bin/sh\n",
    "\n",
    "#SBATCH --job-name=BenchPieVictor\n",
    "#SBATCH --account=sos@a100\n",
    "#SBATCH -C a100\n",
    "\n",
    "#SBATCH --nodes={nbr_node}\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --ntasks-per-node={nbr_gpu}\n",
    "#SBATCH --gres=gpu:{nbr_gpu}\n",
    "\n",
    "#SBATCH --output=output.out\n",
    "#SBATCH --error=error.err\n",
    "\n",
    "#SBATCH --hint=nomultithread\n",
    "#SBATCH --time=00:30:00\n",
    "#SBATCH --qos=qos_gpu-t3\n",
    "\n",
    "{exclu}\n",
    "\n",
    "\n",
    "##conda deactivate\n",
    "module purge\n",
    "\n",
    "## load Pytorch module\n",
    "module load cpuarch/amd\n",
    "module load pytorch-gpu/py3/2.0.1\n",
    "\n",
    "export PATH=/gpfswork/idris/sos/ssos039/.local/bin:$PATH\n",
    "\n",
    "## launch script on every node\n",
    "set -x\n",
    "\n",
    "# code execution\n",
    "srun pie train \\\n",
    "-c ../../config.json \\\n",
    "--model_name {model_name} \\\n",
    "--training_dist {ddp} \\\n",
    "--stage {stage} \\\n",
    "--batch_size {batch_size} \\\n",
    "--seq_length {max_length} \\\n",
    "{debug} \\\n",
    "\"\"\"\n",
    "    return slurm_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43858c5-66db-491e-8ed8-da21ce5b254c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_slurm_file(config):\n",
    "    name = f\"bench_pie\"\n",
    "    for key,value in config.items():\n",
    "        name = name+f\"--{re.sub('[^0-9a-zA-Z]+', '_', str(key))}-{re.sub('[^0-9a-zA-Z]+', '_', str(value))}\"\n",
    "    \n",
    "    path = os.path.join(ORIGIN_DIR, name)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    # shutil.copy(\"/gpfsdswork/projects/idris/sos/ssos039/benchmarks_throughput_OptimDDP_PEFT/benchmarks_optimDDP_peft_bf16/benchmarks_optimDDP_peft_bf16.py\",path)\n",
    "    os.chdir(path)\n",
    "    \n",
    "    with open(f\"slurm_file.slurm\",\"w\") as f:\n",
    "        f.write(write_slurm_string(config))\n",
    "        \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14acd86d-a2e7-4f17-a2be-a2e97d9d767d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def all_combinations(configs):\n",
    "    keys, values = zip(*parameters.items())\n",
    "    comb_parameters = [dict(zip(keys, p)) for p in product(*values)]\n",
    "    combinated_parameters=[]\n",
    "    for i in range(len(comb_parameters)):\n",
    "        combinated_parameters.append(comb_parameters[i])\n",
    "    return combinated_parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65781afa-4ea0-4452-98cf-1f3ebfb826c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def launch_bench(configs):\n",
    "    for config in configs:\n",
    "        name = write_slurm_file(config)\n",
    "        os.system(f\"sbatch slurm_file.slurm\")\n",
    "        print('Last training: ' + name)\n",
    "        sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5945eb15-6772-44c1-81f9-ed886af746c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters={\n",
    "\n",
    "#     'model_name': [\"meta-llama/Llama-2-7b-hf\", \"meta-llama/Llama-2-13b-hf\"],\n",
    "#     'training_dist': [\"deepspeed2\", \"deepspeed3\", \"fsdp\"],\n",
    "#     'nbr_gpu': [4, 8, 16],\n",
    "    \n",
    "#     'batch_size': [1, 2, 4, 8, 16, 32, 64],\n",
    "\n",
    "#     'max_length': [1024],\n",
    "#     'is_debug': [True, False]\n",
    "# }\n",
    "\n",
    "parameters={\n",
    "\n",
    "    'model_name': [\"meta-llama/Llama-2-13b-hf\"],\n",
    "    'training_dist': [\"fsdp\", \"deepspeed3\"],\n",
    "    'nbr_gpu': [16],\n",
    "    \n",
    "    'batch_size': [1, 2, 3],\n",
    "\n",
    "    'max_length': [1024],\n",
    "    'is_debug': [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23a42db7-b41e-4eb1-8e7a-1fc1f36c44a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 1480754\n",
      "Last training: bench_pie--model_name-meta_llama_Llama_2_13b_hf--training_dist-fsdp--nbr_gpu-16--batch_size-1--max_length-1024--is_debug-True\n",
      "Submitted batch job 1480757\n",
      "Last training: bench_pie--model_name-meta_llama_Llama_2_13b_hf--training_dist-fsdp--nbr_gpu-16--batch_size-2--max_length-1024--is_debug-True\n",
      "Submitted batch job 1480758\n",
      "Last training: bench_pie--model_name-meta_llama_Llama_2_13b_hf--training_dist-fsdp--nbr_gpu-16--batch_size-3--max_length-1024--is_debug-True\n",
      "Submitted batch job 1480759\n",
      "Last training: bench_pie--model_name-meta_llama_Llama_2_13b_hf--training_dist-deepspeed3--nbr_gpu-16--batch_size-1--max_length-1024--is_debug-True\n",
      "Submitted batch job 1480762\n",
      "Last training: bench_pie--model_name-meta_llama_Llama_2_13b_hf--training_dist-deepspeed3--nbr_gpu-16--batch_size-2--max_length-1024--is_debug-True\n",
      "Submitted batch job 1480763\n",
      "Last training: bench_pie--model_name-meta_llama_Llama_2_13b_hf--training_dist-deepspeed3--nbr_gpu-16--batch_size-3--max_length-1024--is_debug-True\n"
     ]
    }
   ],
   "source": [
    "all_configs = all_combinations(parameters)\n",
    "launch_bench(all_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed615f-d1ca-4333-af6e-dd1c35632b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-2.0.1_py3.10.12",
   "language": "python",
   "name": "module-conda-env-pytorch-gpu-2.0.1_py3.10.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
